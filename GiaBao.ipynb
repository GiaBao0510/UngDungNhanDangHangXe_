{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Thêm thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Đường dẫn và mảng lưu trữ tên lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Class/\"\n",
    "categories = ['Audi', 'hyundai', 'lexus', 'mazda', 'Mercedes', 'toyota', 'volkswagen','opel']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Khởi tạo dữ liệu và lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []       #\n",
    "labels = []     #Lưu chỉ số lớp\n",
    "imagePaths = [] #Lưu trữ đường dẫn ảnh và chỉ số nhãn về nó\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "\n",
    "N_CHANNELS = 3 #Kênh màu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.Xáo trộn đường dẫn 1 cách ngẫu nhiên lưu vào mảng \"data\" và đưa các hình ảnh về chung chuẩn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Class/Mercedes/Mercede (763).jpg', 4], ['Class/mazda/5401335763581300412_rotate_90_73.jpg', 3], ['Class/volkswagen/vw-3306790_960_720_rotate_90_263.jpg', 6], ['Class/Mercedes/mercede (502).jpg', 4], ['Class/Mercedes/mercede (594).jpg', 4], ['Class/Audi/audi (1517).jpg', 0], ['Class/lexus/images117.jpg', 2], ['Class/Mercedes/mercede (305).jpg', 4], ['Class/Mercedes/mercede (201).jpg', 4], ['Class/Audi/audi (770).jpg', 0]]\n",
      "Labels\n",
      "[0 5 4 ... 4 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Lưu đường dẫn và lớp và mảng imagePaths\n",
    "for index ,name in enumerate(categories):\n",
    "    for file in os.listdir(path+name):\n",
    "        imagePaths.append([path+name+'/'+file, index])\n",
    "\n",
    "#Xáo trộn dữ liệu\n",
    "import random\n",
    "random.shuffle(imagePaths)\n",
    "print(imagePaths[:10])\n",
    "\n",
    "#Đưa các hình ảnh về kích cỡ tiêu chuẩn\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath[0])            #Đọc hình ảnh thông qua đường dẫn\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))  #resize hình ảnh\n",
    "    data.append(image)\n",
    "\n",
    "    labels.append( int(imagePath[1]) )               #Lưu chỉ số theo ngẫu nhiên\n",
    "\n",
    "\n",
    "#Tiền xử lý dữ liệu\n",
    "data = np.array(data, dtype='float')/255\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Labels')\n",
    "print(labels)\n",
    "# print('Data')\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5# Chia tập dữ liệu</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14231, 32, 32, 3)\n",
      "(6100, 32, 32, 3)\n",
      "(14231, 8)\n",
      "(6100,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "#Tiền xử lý các lớp\n",
    "Y_train = utils.to_categorical(Y_train, num_classes=len(categories))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. Các thông số quan trọng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 35  #Số lần học lại\n",
    "BS = 24 #Số cụm học\n",
    "INIT_LR = 1e-3\n",
    "\n",
    "class_name = categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7.Mô hình kiến trúc xây dựng lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "WARNING:tensorflow:From c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "593/593 [==============================] - 26s 37ms/step - loss: 1.4920 - accuracy: 0.4246\n",
      "Epoch 2/35\n",
      "593/593 [==============================] - 21s 36ms/step - loss: 0.8751 - accuracy: 0.6952\n",
      "Epoch 3/35\n",
      "593/593 [==============================] - 21s 35ms/step - loss: 0.3948 - accuracy: 0.8708\n",
      "Epoch 4/35\n",
      "593/593 [==============================] - 21s 35ms/step - loss: 0.1767 - accuracy: 0.9459\n",
      "Epoch 5/35\n",
      "593/593 [==============================] - 22s 37ms/step - loss: 0.1018 - accuracy: 0.9701\n",
      "Epoch 6/35\n",
      "593/593 [==============================] - 22s 37ms/step - loss: 0.0679 - accuracy: 0.9807\n",
      "Epoch 7/35\n",
      "593/593 [==============================] - 22s 37ms/step - loss: 0.0397 - accuracy: 0.9889\n",
      "Epoch 8/35\n",
      "593/593 [==============================] - 21s 35ms/step - loss: 0.0592 - accuracy: 0.9821\n",
      "Epoch 9/35\n",
      "593/593 [==============================] - 22s 37ms/step - loss: 0.0422 - accuracy: 0.9878\n",
      "Epoch 10/35\n",
      "593/593 [==============================] - 25s 43ms/step - loss: 0.0506 - accuracy: 0.9838\n",
      "Epoch 11/35\n",
      "593/593 [==============================] - 19s 32ms/step - loss: 0.0395 - accuracy: 0.9892\n",
      "Epoch 12/35\n",
      "593/593 [==============================] - 16s 27ms/step - loss: 0.0322 - accuracy: 0.9902\n",
      "Epoch 13/35\n",
      "593/593 [==============================] - 16s 26ms/step - loss: 0.0353 - accuracy: 0.9902\n",
      "Epoch 14/35\n",
      "593/593 [==============================] - 16s 27ms/step - loss: 0.0259 - accuracy: 0.9935\n",
      "Epoch 15/35\n",
      "593/593 [==============================] - 16s 26ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "Epoch 16/35\n",
      "593/593 [==============================] - 16s 27ms/step - loss: 0.0374 - accuracy: 0.9885\n",
      "Epoch 17/35\n",
      "593/593 [==============================] - 15s 26ms/step - loss: 0.0348 - accuracy: 0.9916\n",
      "Epoch 18/35\n",
      "593/593 [==============================] - 16s 27ms/step - loss: 0.0212 - accuracy: 0.9944\n",
      "Epoch 19/35\n",
      "593/593 [==============================] - 16s 27ms/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 20/35\n",
      "593/593 [==============================] - 30s 51ms/step - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 21/35\n",
      "593/593 [==============================] - 25s 41ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 22/35\n",
      "593/593 [==============================] - 31s 52ms/step - loss: 0.0124 - accuracy: 0.9965\n",
      "Epoch 23/35\n",
      "593/593 [==============================] - 31s 52ms/step - loss: 0.0287 - accuracy: 0.9914\n",
      "Epoch 24/35\n",
      "593/593 [==============================] - 32s 54ms/step - loss: 0.0192 - accuracy: 0.9948\n",
      "Epoch 25/35\n",
      "593/593 [==============================] - 31s 52ms/step - loss: 0.0115 - accuracy: 0.9968\n",
      "Epoch 26/35\n",
      "593/593 [==============================] - 26s 44ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 27/35\n",
      "593/593 [==============================] - 25s 42ms/step - loss: 0.0206 - accuracy: 0.9951\n",
      "Epoch 28/35\n",
      "593/593 [==============================] - 24s 40ms/step - loss: 0.0135 - accuracy: 0.9961\n",
      "Epoch 29/35\n",
      "593/593 [==============================] - 30s 51ms/step - loss: 0.0176 - accuracy: 0.9964\n",
      "Epoch 30/35\n",
      "593/593 [==============================] - 33s 56ms/step - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 31/35\n",
      "593/593 [==============================] - 23s 39ms/step - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 32/35\n",
      "593/593 [==============================] - 22s 37ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 33/35\n",
      "593/593 [==============================] - 21s 36ms/step - loss: 0.0184 - accuracy: 0.9952\n",
      "Epoch 34/35\n",
      "593/593 [==============================] - 25s 42ms/step - loss: 0.0220 - accuracy: 0.9949\n",
      "Epoch 35/35\n",
      "593/593 [==============================] - 31s 53ms/step - loss: 0.0029 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23003dd7910>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(WIDTH, HEIGHT, N_CHANNELS)))\n",
    "model.add(MaxPooling2D(strides=2))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "model.add(Flatten())        #Chuyền từ 2D or 3D sang 1D\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=INIT_LR, decay=INIT_LR/EPOCH )\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=BS, epochs=EPOCH, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [INFO] compiling model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 75x75; Received: input_shape=(32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [INFO] compiling model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m InceptionV3 \u001b[38;5;241m=\u001b[39m \u001b[43mInceptionV3\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWIDTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHEIGHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m InceptionV3\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m      9\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\applications\\inception_v3.py:138\u001b[0m, in \u001b[0;36mInceptionV3\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas true, `classes` should be 1000; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived classes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_input_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_flatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n",
      "File \u001b[1;32mc:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\applications\\imagenet_utils.py:409\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    403\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input must have 3 channels; Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`input_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m                 )\n\u001b[0;32m    406\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    407\u001b[0m                 input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size\n\u001b[0;32m    408\u001b[0m             ) \u001b[38;5;129;01mor\u001b[39;00m (input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m min_size):\n\u001b[1;32m--> 409\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput size must be at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m                 )\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m require_flatten:\n",
      "\u001b[1;31mValueError\u001b[0m: Input size must be at least 75x75; Received: input_shape=(32, 32, 3)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3, MobileNet, VGG16, DenseNet121, EfficientNetB7#, DensenNet#EfficientNet\n",
    "from tensorflow.keras.layers import Dense , GlobalAveragePooling2D\n",
    "from  keras import layers\n",
    "from keras import models\n",
    "\n",
    "print( \" [INFO] compiling model...\")\n",
    "InceptionV3 = InceptionV3(input_shape=(32, 32, 3), include_top= False, weights= 'imagenet')\n",
    "for layer in InceptionV3.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential()\n",
    "model.add(InceptionV3)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(len(class_name), activation='softmax'))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCH)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics= [\"accuracy\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8. Lưu mô hình và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(None, 32, 32, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m argmax\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, accuracy_score\n\u001b[1;32m----> 6\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m argmax(pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m#trả đến nhãn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(Y_test, predictions) \u001b[38;5;66;03m#Ma trận tương quan\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqw8l29ei.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\VTOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(None, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('inceptionV3.h5')\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "predictions = argmax(pred, axis=1)  #trả đến nhãn\n",
    "\n",
    "cm = confusion_matrix(Y_test, predictions) #Ma trận tương quan\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Model confusion matrix')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels(['']+ categories)\n",
    "ax.set_yticklabels(['']+ categories)\n",
    "\n",
    "for i in range(len(categories)): \n",
    "    for j in range(len(categories)):\n",
    "        ax.text(i, j, cm[i,j], va='center', ha='center')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9. Xác định độ chính xác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.90%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10. Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
